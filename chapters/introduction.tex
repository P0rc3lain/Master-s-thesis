%
%  Copyright © 2022 Mateusz Stompór. All rights reserved.
%

\chapter{Grafika trójwymiarowa}
\section{Początki}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=6cm]{images/people/william-fetter.jpg}    
    \end{center}
    \caption{William Fetter w momencie gdy pracował dla Boeing Aircraft, 1963}
    \label{fig:william-fetter}
\end{figure}

\par % Wyjaśnienie terminu grafika komputerowa
Powszechnie uznaje się, że termin \q{grafika komputerowa} po raz pierwszy został użyty w 1960 roku przez Williama Fetera, ówczesnego pracownika firmy Boeing.
Pełniąc rolę menadżera w zespole zaawansowanych projektów graficznych otrzymał on zadanie wymyślenia nowego sposobu tworzenia rysunków technicznych za pomocą komputera.
W swoim założeniu miały przedstawiać one różne przedmioty opisane w oparciu o punkty w przestrzeni trójwymiarowej z uwzględnieniem zniekształceń perspektywy.
Narzędzie miało nie tylko być w stanie stworzyć pojedynczy rysunek na papierze, ale także sekwencje przedstawiające animacje na taśmie filmowej.
Przekucie idei w działający prototyp zajęło kilka miesięcy. 
Zaprogramowane instrukcje interpretowane były przez autorski aparat matematyczny i przekładane na docelowy materiał za pomocą robotycznego ramienia.
W obrębie firmy rozwiązanie początkowo wykorzystywano do wizualizacji wnętrz kokpitów i pracy nad ich ergonomią.
Ważnym osiągnięciem będącym następstwem do generowania pojedynczych, niepowiązanych ze sobą scen było stworzenie serii rysunków przedstawiających animacje lądującego samolotu.
Pomimo wielu wad, jakimi między innymi były długi czas oczekiwania na wynik czy losowe błędy sprawiające, że rysunek musiał być ponownie wytworzony Fetter dostrzegł potencjał i zdecydował się przedstawić efekt swojej pracy szerszemu gronu odbiorców.
Swój pomysł pokazał światu posługując się sylwetką człowieka, która sięgając ręką do panelu sterowania wewnątrz samolotu ustanowiła początek ery trójwymiarowej grafiki komputerowej jaką znamy dzisiaj.
\par % Pokazanie przykładów i opowiedzenie do czego obecnie może być wykorzystywana
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=6cm]{images/battlezone.jpg}    
        \caption{Battlezone, pierwsza produkcja wykorzystująca grafikę trójwymiarową, 1980}
    \end{center}
    \label{fig:battlezone}
\end{figure}
Technologia, podobnie jak i wiele innych nowatorskich rozwiązań niedługo po ujrzeniu światła dziennego stopniowo zaczęła przechodzić do masowego użytku.
Kamieniem milowym w osi czasu kreślącej rozwój tej dziedziny była publikacja gry Battlezone, która w 1980 roku pozwoliła milionom odbiorców doświadczyć po raz pierwszy animacji przestrzennych brył na płaszczyźnie telewizora.
Nie mniej ważne wydarzenie stanowiła premiera filmu \q{Toy story} z 1995 roku. 
Studio Pixar przewodzone w owym czasie przez Steve'a Jobsa wykonało pełnometrażową produkcję opartą w całości o wykorzystanie technik modelowania komputerowego i generowania cyfrowego obrazu trójwymiarowego.

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=6cm]{images/toy-story.jpeg}    
        \caption{Klatka podglądu oraz finalna z filmu \q{Toy Story}, 1995}
    \end{center}
    \label{fig:toy-story}
\end{figure}

Zapisaniem się w historii i pionierstwem w dziedzinie projektowania pochwalić może się firma Boeing.
Składający się z ponad 3 milionów części samolot serii 777 pokazał pierwszym lotem w 1994 roku, że za pomocą komputerów nie tylko skraca się czas przeznaczony na rozwój, ale także zmniejsza ilość pomyłek i zwiększa bezpieczeństwo~\cite{agile_at_boeing}.
Wymienione wydarzenia stanowiły przełom w swoich branżach.
Nie sposób jednak określić jednoznacznej przynależności trójwymiarowej grafiki komputerowej.
Niewątpliwymi filarami napędzającymi rozwój są przytoczone gry komputerowe, branża filmowa i szeroko rozumiany przemysł projektowania, szacowane na odpowiednio 220~\cite{games_market_share}, 80~\cite{movies_market_share} i 50~\cite{interior_design_market_share} miliardów dolarów w rocznym ujęciu globalnym.

\section{Podział grafiki}
% Rozróżnienie pomiędzy grafiką czasu rzeczywistego a nierzeczywistego
Wspomniane gałęzie rozwoju - gry komputerowe oraz filmy - kładą nacisk na wykluczające się między sobą czynniki.
Pierwsza z nich skupia się na wydajności koniecznej do zapewnienia interaktywności.
Kluczowym w tym kontekście jest określenie grupy docelowej w znaczeniu możliwości sprzętu.
Produkt dostosowywany jest pod uprzednio zadane zasoby, a w sytuacji gdy dany efekt graficzny skutkuje w spadkach wydajności - jest usuwany.
Z drugiej strony branża filmowa koncentruje się na jakości obrazu.
Odbiorca nie ma wpływu na akcję, przebieg sekwencji wydarzeń każdorazowo wygląda w ten sam sposób.
Restrykcja czasowa, której podlega generowanie kolejnych klatek jest praktycznie zaniedbywalna.
Wynika to z faktu, że fragmenty animacji tworzone mogą być niezależnie od siebie, równolegle, na wielu maszynach.
W przeciwieństwie do gier komputerowych ich wytwarzanie dokonywane jest dokładnie raz, a następnie tylko podlega odtwarzaniu.
Interaktywność jest cechą, która odróżnia grafikę czasu rzeczywistego od nierzeczywistego i wprowadza główne rozróżnienie pomiędzy technologiami służącymi do produkcji obrazu.

\section{Organizacja obiektów}
% Wyjaśnienie podstawowych pojęć opisu elementów na scenie
Generowania dwuwymiarowych obrazów za pomocą komputera przypomina proces tworzenia filmów.
Nie dziwi więc fakt, że znaczna część pojęć używanych w odniesieniu do zawartości klatki czerpie właśnie z niego.
Nadrzędnym elementem zawierającym w sobie wszystkie pomniejsze jest scena.
W niej zorganizowani są aktorzy rozumiani jako postacie bezpośrednio mające wpływ na akcje, jak i pozostałe fragmenty scenerii stanowiące tło.
Za uwiecznienie trwających wydarzeń odpowiedzialne są kamery, które przedstawiają świat z różnych perspektyw.
W zależności od wizji twórczej może być ich różna ilość, zawsze jednak tylko jedna rozpatrywana jest jako aktywna, a więc przekazująca aktualny obraz.
Niezbędnym elementem, który konieczny jest, aby obserwator był w stanie dostrzec cokolwiek jest źródło światła.
Zaliczamy do nich wszystkie emitery, takie jak słońce, księżyc, ogień, czy żarówki elektryczne.
\par Początkowo implementacja idei była bezpośrednia. 
Struktura sceny była płaska, a obiekty były od siebie niezależne.
Podejście obarczone było pewnymi negatywnymi konsekwencjami.
Najłatwiej dostrzec je posługując się przykładem.
W tym celu rozważony zostanie fragment krótkiego scenariusza.
\begin{quote} 
    \centering 
    \q{Człowiek porusza się po lesie zbierając jagody do koszyka}
\end{quote}
Pragnąc zrealizować animację za pomocą komputera należałoby przygotować kilka modeli - lasu, człowieka, koszyk oraz jagody.
Podział w ten sposób podyktowany jest chęcią sprawienia, aby modele były możliwe do użycia w innych konfiguracjach - sceneria pola zamiast lasu, poziomki w miejsce jagód.
Dodatkowo, uczynienie ich niepodległymi sobie sprawia, że modyfikacja ich położenia jest ułatwiona. 
Zakładając, że nie istnieje relacja posiadania pomiędzy obiektami ruch jagód, człowieka oraz koszyka byłby od siebie niezależny.
W celu zachowania immersji koniecznym byłoby nanoszenie korekt pozycji jagód i koszyka za każdym razem gdy pozycja człowieka ulegnie zmianie.
Jasnym staje się, że pomiędzy obiektami zachodzi relacja i ruch nadrzędnego elementu - człowieka - powinien mieć wpływ na podrzędne - koszyk, jagody.
W efekcie ruchu człowieka zmiana położenia koszyka, jak i znajdujących się w nim jagód powinna następować automatycznie.
Realizacja tego pomysłu dała początek hierarchicznym grafom sceny, które wynaleziono w latach 90-tych i wykorzystywane są do dzisiaj.
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=15cm]{images/scene-graph.png}    
        \caption{Graf sceny przedstawiający hierarchię pomiędzy obiektami}
    \end{center}
    \label{fig:scene-graph}
\end{figure}
\section{Układy współrzędnych}
Wspominając o dwuwymiarowym układzie kartezjańskim przywołać można obraz pary osi prostopadłych do sobie.
Oś \textit{x} usytuowana jest w taki sposób, że wartości opisujące współrzędne punktu rosną w prawą stronę.
W przypadku osi \textit{y} kolejne, następujące po sobie liczby pną się w górę.
Wprowadzenie kolejnej koordynaty i rozszerzenie układu na potrzeby trójwymiarowości pozostawia pewną dowolność.
Dodatkowa oś - \textit{z} - będąca prostopadłą do dwóch poprzednich może skierowana być \textit{do ekranu} lub \textit{od ekranu}.
W zależności od wybranej opcji mówić można o praworęcznym lub leworęcznym układzie współrzędnych - kciuk oraz palec wskazujący tworzą osie \textit{xy}, zaś środkowy \textit{z}.
Żadna nie przewyższa drugiej w kontekście użycia, natomiast istotnym jest aby w obliczeniach pozostać przy raz wybranej konwencji.
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=10cm]{images/lh-rh-coordinate-systems.png}
        \caption{Wizualizacja idei leworęcznego oraz praworęcznego układu współrzędnych}
    \end{center}
    \label{fig:lh-rh-cs}
\end{figure}
\par
Punkt opisany jest w odniesieniu do pewnego układu współrzędnych.
Ten jednak, jak wyjaśniono w poprzedniej sekcji zagnieżdżony może być w innych.
Część z nich jest na tyle istotna, że nie pozostają anonimowe i powiązane są z konkretną nazwą.
Wyróżnić można kilka najważniejszych:
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=5cm]{images/coordinate-spaces.jpg}    
        \caption{Przedstawienie mnogości układów współrzędnych na scenie}
    \end{center}
    \label{fig:coordinate-spaces}
\end{figure}

\paragraph{Układ styczny \eng{Tangent Space}} Wektory bazowe składają się z wektora normalnego do zadanego wierzchołka oraz rozpinającego przestrzeń tangensa oraz bitangensa.

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=5cm]{images/tangent-space.jpg}
        \caption{Układ styczny opisany na jednym z wierzchołków sfery}
    \end{center}
    \label{fig:tangent-space}
\end{figure}

\paragraph{Układ modelu \eng{Model Space}} Powiązany jest z siatką modelu jako całością bądź jej mniejszymi fragmentami.
Pomimo występującej hierarchii w samym modelu pomniejsze układy nie rozróżniane są za pomocą oddzielnych terminów.
\paragraph{Układ świata \eng{World Space}} Tworzy korzeń hierarchii w odniesieniu do którego opisane są pozostałe układy.
\paragraph{Układ kamery \eng{Camera Space}} Osadza kamerę w początku układu współrzędnych. Z jego poziomu generowana jest klatka obrazu.
\paragraph{Układ przycinania \eng{Clip Space}} Jest bezpośrednim następcą układu kamery, z którego przejście nastąpiło na skutek projekcji.
W przypadku metal jest to leworęczny układ współrzędnych zadany prostopadłościanem o głębokości \textit{1} i powierzchni bocznej opisanej przy pomocy kwadratu o boku \textit{2}.
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=5cm]{images/coordinate-systems/ndc.png}
        \caption{Prostopadłościan opisujący znormalizowany układ współrzędnych w Metal}
    \end{center}
    \label{fig:ndc-metal}
\end{figure}
\paragraph{Układ okna \eng{Window Space}} Stanowi dyskretną przestrzeń dwuwymiarowa stojąca na szczycie w hierarchii generowania grafiki, rozciągająca się na całej powierzchni warstwy użytej do wyświetlenia obrazu.
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=5cm]{images/coordinate-systems/device-viewport.png}
        \caption{Układ współrzędnych reprezentujący ekran urządzenia}
    \end{center}
    \label{fig:device-viewport}
\end{figure}
\section{Grafika akcelerowana sprzętowo}
Posiadając uprzednio zaaranżowaną scenę możliwe jest jej uwiecznienie.
Przekład modeli opisanych w trójwymiarowym układzie współrzędnych na dwuwymiarowy obraz nazywamy renderowaniem.
Początkowo algorytmy realizujące to zadanie w całości oparte były o wykorzystanie procesora CPU.
Charakter operacji matematycznych wykonywanych na poszczególnych modelach występujących w ramach kadru pokazywał jednak, że są one powtarzalne i nie występują między nimi zależności.
Naturalnym krokiem mającym na celu przyspieszenie operacji było stworzenie modułu, który za pomocą predefiniowanych operacji zrealizuje zadanie.
Urządzenia spełniające tę role nazywane są GPU \eng{graphics processing unit}.
Ze względu na fakt, że oddzielone są od procesora, koniczne było także zapewnienie drogi komunikacji pomiędzy programistami, a jednostką.
Pierwsze API \eng{application programming interface} realizowały stosunkowo szeroki zakres funkcjonalności.
Zadanie twórcy sprowadzało się do zapewnienia modeli i rozmieszczenia ich na scenie, kalkulacja wpływu światła na poszczególne obiekty lub zasób materiałów wpływających na charakterystykę pokrywających ich powierzchni spoczywał na module akceleracyjnym.
Choć z początku podejście wydawało się być wygodne bowiem programista nie musiał rozumieć aparatu matematycznego stanowiącego bazę dla technologii, to szybko okazało się, że wysoko poziomowy interfejs jest ograniczeniem.
Artyści nie byli w stanie realizować swoich wizji.
Akceleratory zapewniały możliwość tworzenie grafik tylko i wyłącznie w oparciu o pewien charakter.
Nie istniała możliwość zmiany algorytmu kalkulacji wpływu światła na obiekt czy choćby dodanie filtra na obraz.
W efekcie wiele produkcji z lat początków sprzętowej akceleracji jest podobna do siebie pod względem wyglądu.
Odpowiedzią na to zjawisko było wprowadzenie jawnego potoku renderowania, którego część kroków podlegała modyfikacji.
W szczególności niektóre z nich mogą być w pełni programowane przy użyciu specjalnego języka.
\section{API}
Niezmiennie od początku istnienia technologii do zakresu nałożonych nań obowiązków zaliczamy przekazywanie polecań wydanych przez programistę za pośrednictwem sterownika karty graficznej do jej procesora.
Współczesne rozwiązania, takie jak Metal, Direct X czy Vulkan pochwalić mogą się szerszym wachlarzem funkcjonalności.
Przede wszystkim wprowadzają dodatkową warstwę abstrakcji.
Choć producenci stosują autorskie architektury to API sprawia, że różnice w ich działaniu mogą być dla twórców oprogramowania zaniedbywalne.
Pełne uspójnienie interfejsu jest niemożliwe, ze względu na występujące sprzętowe rozbieżności, jednak w znacznej mierze dostępne instrukcje stanowiące trzon nie podlegają zmianom.
\par 
Używane obecnie technologie opisywane są jako niskopoziomowe.
W odróżnieniu od koncepcji przypadających na pierwsze lata rozwoju pomysłu współcześnie użytkownicy operują na buforach, programach cieniujących czy kolejkach komend zamiast pierwotnych, wysokopoziomowych rozkazach dotyczących zarządzaniem sceną.
Te, choć nadal obecne są we współczesnych programach, stanowią inwencję programistów korzystających z API w celu budowania łatwiejszego do zrozumienia dlań kodu.
\par
Pomimo różnic pomiędzy dostępnymi API, a także ich wariantami główny schemat wykorzystania pozostaje spójny.
Może zostać opisany następującym algorytmem:
\begin{enumerate}
    \item Inicjalizacja API
    \item Wczytywanie zewnętrznych zasobów - modele, tekstury, filmy, itp.
    \item Aktualizacja zasobów
    \item Prezentacja
    \item Powtórzenie \textit{2}, \textit{3} oraz \textit{4} do momentu zatrzymania programu
    \item Destrukcja
\end{enumerate}
Ważnym atutem jest możliwość tworzenia kodu wykorzystującego zasoby karty graficznej i testowania go na konsumenckim sprzęcie.
Jeśli jednostka graficzna obsługuje technologię API, wówczas zakładając posiadanie podstawowych narzędzi deweloperskich można jej użyć we własnej produkcji.

% Opisz:
% * wsparcie dla wielu kart graficznych
% * wskaż komendy asynchroniczne
% * programy cieniujące

\section{Potok renderowania}
Moc obliczeniowa karty graficznej wykorzystywana może być w dwojaki sposób.
Pierwszy, coraz częściej spotykany polega na użyciu procesora grafiki w celu przeprowadzenia dowolnych rachunków o charakterze współbieżnym.
Służy to odciążeniu zasobów procesora CPU przy jednoczesnym zwiększeniu wydajności ze względu na oddelegowanie pracy do jednostki będącej lepiej przystosowaną do tego typu zadania.
Idea określana jest mianem GPGPU \eng{General-Purpose GPU}, a więc służy wykonaniu pracy nienastawionej bezpośrednio na tworzenie obrazu.
Drugi, tradycyjny typ użycia to skorzystanie z wbudowanego potoku renderowania.
Choć interfejsy API charakteryzują się subtelnymi różnicami, to kroki obecne podczas procesu pozostają niezmienne.
\par
Potok renderowania przedstawiony i omówiony zostanie na podstawie ilustracji dotyczącej specyfikacji technologii Metal.
Etapy będące jego częścią następują bezpośrednio po sobie i mają charakter sekwencyjny.
Część z nich nie podlega żadnej konfiguracji, inne mogą być parametryzowane w ograniczony sposób.
Te kluczowe są w pełni modyfikowalne, a logika ich działania dostarczana jest w formie programu komputerowego. 
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=15cm]{images/metal-rendering-pipeline.png}    
        \caption{Potok renderowania wykorzystywany w języku Metal, Apple Inc.}
    \end{center}
    \label{fig:metal-rendering-pipeline}
\end{figure}
\paragraph*{Figury \eng{Primitives}}
Pierwszy krok stanowi wejście do potoku renderowania.
Dane pobierane są z określonego przez użytkownika bufora danych i przetwarzane jako punkty, w przestrzeni dwu, trzy lub czterowymiarowej.
Dalszemu procesowaniu podlegać mogą w niezmienionej formie, być interpretowane jako linie, trójkąty lub łączone w kilka innych figur.
Określenie w jaki sposób mają być ze sobą spajane, o ile taka potrzeba zachodzi, ma kluczowy wpływ na ich dalszy wygląd po procesie rasteryzacji.
\paragraph*{Cieniowanie wierzchołkowe \eng{Vertex Function}}
Cieniowanie wierzchołków jest pierwszym w pełni konfigurowalnym etapem potoku.
Użytkownik dostarcza kod źródłowy realizujący zadanie w postaci pliku \textit{.metal}, który kompilowany jest do instrukcji maszynowych procesora GPU.
Rdzenie uruchamiają program niezależnie dla wierzchołków znajdujących się w buforze danych do momentu przeprocesowania każdego z nich.
Oczekiwanym wynikiem będącym bezpośrednim efektem działania algorytmu jest określenie ostatecznej pozycji wierzchołka w odniesieniu do obiektywu kamery.
Przez wzgląd na fakt, że aranżacja sceny i jej wymiary są cechami indywidualnymi dla poszczególnych projektów zachodzi potrzeba wykorzystania generycznego mechanizmu, który pozwoli określić jak pozycja wierzchołka koresponduje do powierzchni na której jest wyrysowywana.
Zadanie to realizowane jest za pomocą użycia znormalizowanego układu współrzędnych urządzenia.
W tym celu pozycja wierzchołka w układzie współrzędnych kamery rzutowana jest na wspominany układ urządzenia.
Jeśli pozycja wierzchołka znajduje się wewnątrz graniastosłupa ograniczającego ten układ wierzchołek kontynuuje drogę przez potok, w przeciwnym razie jest odrzucany.
\paragraph*{Rasteryzacja \eng{Rasterization}}
Zadaniem rasteryzacji jest rozwiązanie problemu widzialności~\cite{rasterization_implementation}.
Aktualnie procesowane koordynaty wierzchołków rzutowane są na dyskretny układ współrzędnych obrazu wyjściowego.
W zależności od wybranego typu figury geometrycznej, która ma zostać stworzona na podstawie wierzchołków algorytm przybiera nieco inną formę.
W przypadku trójkątów jeżeli pole figury ma kontakt z pikselem obrazu wyjściowego wówczas jest on włączany do dalszego procesowania, w przeciwnym razie algorytm kończy działanie.
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=4cm]{images/pipeline/rasterization.png}    
        \caption{Przedstawienie idei procesu rasteryzacji}
    \end{center}
    \label{fig:pipeline-rasterization}
\end{figure}
\paragraph*{Cieniowanie Fragmentów \eng{Fragment Function}}
Piksele, które służą do opisu figury po procesie rasteryzacji określane są mianem fragmentów.
Każdy uprzednio nieodrzucony poddany może być dalszej modyfikacji.
Stanowi to kolejny, w pełni konfigurowalny etap potoku.
Podobnie jak w przypadku cieniowania wierzchołków użytkownik jest zobowiązany do zapewnienia funkcji stworzonej w oparciu o MSL \eng{Metal Shading Language}.
W tradycyjnym podejściu odpowiada ona za określenie wpływu światła na geometrię.
Dzięki temu obserwator jest w stanie dostrzec w jaki sposób oświetlenie usytuowane na scenie oddziałuje na model.
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=6cm]{images/phong-shading.jpeg}    
        \caption{Cieniowanie na przykładzie algorytmu Phonga}
    \end{center}
    \label{fig:phong-shading}
\end{figure}
\paragraph*{Przycinanie \eng{Scissor}}
Zdarza się, że generowany obraz powinien być zaprezentowany w częściowej formie.
W takim wypadku programista może określić obszar obrazu, który powinien zostać utrwalony.
Fragmenty usytuowane poza nim nie będą zapisywane na wyjściu.
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=6cm]{images/pipeline/scissoring.png}
        \caption{Przycinanie na przykładzie obrazu trójkąta}
    \end{center}
    \label{fig:scissoring}
\end{figure}
\paragraph*{Wielopróbkowanie \eng{Multisample}}
Następnym, opcjonalnym krokiem w potoku renderowania jest wielopróbkowanie.
Celem, którym ma być zrealizowany jest wygładzenie krawędzi pomiędzy różnymi obiektami na obrazie wyjściowym.
Efekt osiągany jest za pomocą zmiany sposobu działania algorytmu rasteryzacji.
Zamiast opierać się na pojedynczym punkcie do określenia czy figura pokrywa dany fragment używana jest ich większa ilość.
Cieniowanie fragmentów wciąż wykonywane jest tylko i wyłącznie dla pojedynczego elementu, jednak kolor wyjściowy który został uzyskany mieszany jest z tłem w oparciu o dane z próbkowania dla większej liczby punktów.
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=6cm]{images/pipeline/multisampling.png}
        \caption{Zobrazowanie idei wielopróbkowania}
    \end{center}
    \label{fig:multisampling}
\end{figure}
\paragraph*{Test szablonu \eng{Stencil Test}}
Poza wspomnianym przycinaniem użytkownik ma dodatkową możliwość, aby ograniczyć powierzchnie obrazu, która zostanie zaprezentowana.
Operacja dokonywana jest z wysoką ziarnistością - dla każdego piksela obrazu.
W tym celu wykorzystywane są maski binarne.
Idea działania algorytmu jest prosta.
Jeśli dla zadanego fragmentu wartość w buforze maski wynosi \textit{1} wówczas kontynuuje on drogę przez potok, w przeciwnym wypadku jest odrzucany.
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=4cm]{images/pipeline/binary-mask.png}
        \caption{Przykład maski binarnej opisującej kształtem balon}
    \end{center}
    \label{fig:binary-mask}
\end{figure}
\paragraph*{Test głębi \eng{Depth Test}}
W dalszej kolejności wykonywany jest test widoczności.
Jego celem jest sprawdzenie czy dany fragment nie został przesłonięty przez inny.
Zachodzi potrzeba, aby karta graficzna skorzystała z dodatkowego bufora.
Wartości w nim przechowywane odpowiadają odległości poszczególnych fragmentów od obiektywu kamery.
Im dalej się on znajduje - tym liczba jest większa.
W najczęstszym przypadku zadanie testu polega na wykonaniu pojedynczej operacji porównania - wartości zapisanej w buforze z aktualną, obliczoną dla obecnie procesowanego fragmentu.
\paragraph*{Wynik widoczności \eng{Visibility Result}}
Uprzednio wyliczony wynik z działania testu głębi zachowany jest w postaci liczby binarnej.
Widoczny fragment powiązywany jest z wartością \textit{prawda}, \textit{fałsz} przypisywany jest w przeciwnym przypadku.
\paragraph*{Mieszanie \eng{Blend}}
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=6cm]{images/pipeline/blending.png}
        \caption{Mieszanie kolorów. Zobrazowanie braku przemienności operacji}
    \end{center}
    \label{fig:blending}
\end{figure}
Ostatnim krokiem w procesie renderowania jest mieszanie.
Uruchamiane jest ono zawsze, jednak zauważalne rezultaty przynosi w przypadku gdy kolor zadanego fragmentu charakteryzuje się stopniem przeźroczystości.
W celu wykonania obliczenia rozpatrywany jest wynik widoczności po procesie testowania głębi, kolor nowo wygenerowanego fragmentu oraz ten, który już znajduje się w buforze.
Przez wzgląd na brak przemienności operacji istotnym jest aby charakteryzujące się przeźroczystością modele wyrysowywane były od znajdującego się najdalej kamery do najbliższego.
\paragraph*{Bufor wyjścia \eng{Attachment}}
W podstawowym przypadku na bufor wyjścia składają się bufory koloru, głębi oraz szablonu. 
Nie jest jednak to jedyna dozwolona kombinacja.
Bufory głębi oraz szablonu są opcjonalne i o ile aktywne są unikalne.
Załączników koloru natomiast może występować większa ilość.
\newline
\par
Opisany powyżej przepływ wierzchołków modelu przez poszczególne etapy generowania klatki utożsamiany powinien być z pojęciem \textit{single-pass rendering}. 
Termin oznacza, że stworzenie obrazu z modelem reprezentowanym w finalnej formie potrzebuje uruchomienia potoku dokładnie jeden raz.
Współcześnie tego rodzaju podejście jest rzadko stosowane.
Wynika to zarówno z wynalezienia bardziej efektywnych technik renderowania - poprzez zwiększenie ilości wywołania potoku z mniej wymagającymi obliczeniami, co charakteryzuje się wyższą wydajnością.
Ponadto, chęć polepszenia walorów wizualnych wymaga generowania tymczasowych, pośrednich klatek.
W efekcie okazuje się, że stworzenie pojedynczego wycinka animacji wiązać się może z dziesiątkami wywołań potoku.
Nie mniej jednak przywołanie podstawowej formy algorytmu pozwala wyjaśnić jaka koncepcja stoi za utylizacją GPU.
% Tutaj opisać, że mimo wszystko nie tłumaczone było to na marne bo potok jest cały czas używany
% Dodatkowo wskazać, że teraz te dwie formy renderowania się przenikają bo mamy rendering hybrydowy
% Opisz jakie gałęzie matematyki są najczęściej wykorzystywane
% \section{Aparat matematyczny}
\section{Koncept biblioteki graficznej}
Utworzenie standardów obsługi GPU takich jak \textit{OpenGL} czy \textit{Direct X} znacznie odciążyło twórców oprogramowania wykorzystujących trójwymiarowość.
Umożliwiło im rozwijanie swoich pomysłów bez konieczności zapewnienia osobnego wsparcia dla każdego z dostępnych na rynku urządzeń.
Rozwiązanie problemu obnażyło jednak inny, coraz mocniej widoczny na horyzoncie.
Deweloperzy aplikacji i gier w miarę upływu czasu wytwarzali nowe produkty.
Te jednak miały między sobą pewne podobieństwo jakim było generowanie obrazu trójwymiarowego.
Nieefektywnym było tworzenie szablonu modułu graficznego od zera dla każdej produkcji.
Zarówno przez wzgląd na czas jakiego wymaga rozwój, jak i fakt, że oczekiwania w stosunku do możliwości charakteryzowały się podobieństwem.
Wydaje się, że optymalnym rozwiązaniem byłoby wytworzenie kodu odpowiedzialnego za obsługę renderowania raz, a następnie używanie go we wszystkich innych produkcjach potrzebujących tej funkcjonalności.
Jawne kopiowanie wymaganych fragmentów programu byłoby naiwne i obarczone wieloma problemami.
Powszechną praktyką w takiej sytuacji jest stworzenie osobnego projektu skupiającego się na realizacji ściśle ograniczonych funkcji i dystrybuowanie go w formie biblioteki.
Twórcom gier oraz aplikacji daje to możliwość poświęcenia uwagi faktycznemu budowaniu ich produktu, a nie infrastruktury potrzebnej do jego działania.
Jednocześnie biblioteka potencjalnie zapewnić może wysoką jakość oraz wydajność przez wzgląd na powszechne przyjęcie.
\par
Zakres wymagań, który stawiany jest bibliotekom różni się w zależności od projektu.
Przywołać można jednak kilka najważniejszych, przewijających się zawsze:
\begin{itemize}
    \item Nieprzytłaczające złożonością API
    \item Dokumentacja obejmująca sygnatury funkcji i przykłady użycia
    \item Wczytywanie modeli z pliku za pośrednictwem różnych formatów
    \item Kreowanie sceny za pomocą kamer, świateł, siatek oraz materiałów
    \item Manipulowanie obiektami na scenie
    \item Możliwość dokonywania interakcji w czasie rzeczywistym z raz utworzoną sceną
\end{itemize}
Z uwagi na fakt, że współczesny trend skupiający się na tworzenia coraz bardziej efektownych, wolnych od błędów produktów sprawia, że firmy chcące stworzyć tytuł rzadziej decydują się na własnoręczny rozwój modułu graficznego.
Naturalnym wnioskiem jest spostrzeżenie, że warto inwestować w te technologie, ponieważ rzesza potencjalnych odbiorców stale rośnie.
